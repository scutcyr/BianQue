# [æ‰é¹Šï¼ˆBianQueï¼‰]((https://github.com/scutcyr/BianQue))
<p align="center">
    <img src="./ProactiveHealthGPT.png" width=900px/>
</p>
<p align="center">
    <a href="./LICENSE"><img src="https://img.shields.io/badge/license-Apache%202-red.svg"></a>
    <a href="support os"><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href="https://github.com/scutcyr/BianQue/graphs/contributors"><img src="https://img.shields.io/github/contributors/scutcyr/BianQue?color=9ea"></a>
    <a href="https://github.com/scutcyr/BianQue/commits"><img src="https://img.shields.io/github/commit-activity/m/scutcyr/BianQue?color=3af"></a>
    <a href="https://github.com/scutcyr/BianQue/issues"><img src="https://img.shields.io/github/issues/scutcyr/BianQue?color=9cc"></a>
    <a href="https://github.com/scutcyr/BianQue/stargazers"><img src="https://img.shields.io/github/stars/scutcyr/BianQue?color=ccf"></a>
</p>

åŸºäºä¸»åŠ¨å¥åº·çš„ä¸»åŠ¨æ€§ã€é¢„é˜²æ€§ã€ç²¾ç¡®æ€§ã€ä¸ªæ€§åŒ–ã€å…±å»ºå…±äº«ã€è‡ªå¾‹æ€§å…­å¤§ç‰¹å¾ï¼Œåå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢-å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å¼€æºäº†ä¸­æ–‡é¢†åŸŸç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPTï¼ŒåŒ…æ‹¬ï¼š
* ç»è¿‡åƒä¸‡è§„æ¨¡ä¸­æ–‡å¥åº·å¯¹è¯æ•°æ®æŒ‡ä»¤å¾®è°ƒçš„[ç”Ÿæ´»ç©ºé—´å¥åº·å¤§æ¨¡å‹æ‰é¹Šï¼ˆBianQueï¼‰](https://github.com/scutcyr/BianQue)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„[å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰](https://github.com/scutcyr/SoulChat)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**ç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPT** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨æ…¢æ€§ç—…ã€å¿ƒç†å’¨è¯¢ç­‰ä¸»åŠ¨å¥åº·é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º **ç”Ÿæ´»ç©ºé—´å¥åº·å¤§æ¨¡å‹æ‰é¹Šï¼ˆBianQueï¼‰** ã€‚

## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2023.07.07: å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰åœ¨çº¿å†…æµ‹ç‰ˆæœ¬å¯ç”¨ï¼Œæ¬¢è¿ç‚¹å‡»é“¾æ¥ä½¿ç”¨ï¼š[çµå¿ƒå†…æµ‹ç‰ˆ](https://soulchat.iai007.cloud/)ã€‚
- ğŸ‘ğŸ»  2023.07.01: æ„Ÿè°¢[PULSE]([PULSE](https://github.com/openmedlab/PULSE))å›¢é˜Ÿæä¾›çš„Eloè¯„æµ‹ï¼Œç‚¹å‡»[é“¾æ¥](https://github.com/openmedlab/PULSE#elo%E8%AF%84%E6%B5%8B)æŸ¥çœ‹è¯¦æƒ…ã€‚
- ğŸ‘ğŸ»  2023.06.24: æœ¬é¡¹ç›®è¢«æ”¶å½•åˆ°[ä¸­å›½å¤§æ¨¡å‹åˆ—è¡¨](https://github.com/wgwang/LLMs-In-China)ï¼Œä¸ºå›½å†…é¦–ä¸ªå¼€æºçš„å…·å¤‡å¤šè½®é—®è¯¢ä¸å»ºè®®èƒ½åŠ›çš„å¥åº·å¤§æ¨¡å‹ã€‚
- ğŸ‘ğŸ»  2023.06.09: å¢åŠ Windowsä¸‹ç¯å¢ƒé…ç½®ï¼Œè¯¦æƒ…è§æœ¬æ–‡ä»¶çš„å°èŠ‚ï¼šã€è¡¥å……ã€‘Windowsä¸‹çš„ç”¨æˆ·æ¨èå‚è€ƒå¦‚ä¸‹æµç¨‹é…ç½®ç¯å¢ƒã€‚
- ğŸ‘ğŸ»  2023.06.06: æ‰é¹Š-2.0æ¨¡å‹å¼€æºï¼Œè¯¦æƒ…è§[BianQue-2.0](https://huggingface.co/scutcyr/BianQue-2)ã€‚
- ğŸ‘ğŸ»  2023.06.06: å…·å¤‡å…±æƒ…ä¸å€¾å¬èƒ½åŠ›çš„çµå¿ƒå¥åº·å¤§æ¨¡å‹SoulChatå‘å¸ƒï¼Œè¯¦æƒ…è§ï¼š[çµå¿ƒå¥åº·å¤§æ¨¡å‹SoulChatï¼šé€šè¿‡é•¿æ–‡æœ¬å’¨è¯¢æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®é›†çš„æ··åˆå¾®è°ƒï¼Œæå‡å¤§æ¨¡å‹çš„â€œå…±æƒ…â€èƒ½åŠ› ](https://huggingface.co/scutcyr/SoulChat)ã€‚
- ğŸ‘ğŸ»  2023.04.22: åŸºäºæ‰é¹Š-1.0æ¨¡å‹çš„åŒ»ç–—é—®ç­”ç³»ç»ŸDemoï¼Œè¯¦æƒ…è®¿é—®ï¼š[https://huggingface.co/spaces/scutcyr/BianQue](https://huggingface.co/spaces/scutcyr/BianQue)
- ğŸ‘ğŸ»  2023.04.22: æ‰é¹Š-1.0ç‰ˆæœ¬æ¨¡å‹å‘å¸ƒï¼Œè¯¦æƒ…è§ï¼š[æ‰é¹Š-1.0ï¼šé€šè¿‡æ··åˆæŒ‡ä»¤å’Œå¤šè½®åŒ»ç”Ÿé—®è¯¢æ•°æ®é›†çš„å¾®è°ƒï¼Œæé«˜åŒ»ç–—èŠå¤©æ¨¡å‹çš„â€œé—®â€èƒ½åŠ›ï¼ˆBianQue-1.0: Improving the "Question" Ability of Medical Chat Model through finetuning with Hybrid Instructions and Multi-turn Doctor QA Datasetsï¼‰](https://huggingface.co/scutcyr/BianQue-1.0)


## æ‰é¹Šå¥åº·å¤§æ•°æ®BianQueCorpus
æˆ‘ä»¬ç»è¿‡è°ƒç ”å‘ç°ï¼Œåœ¨å¥åº·é¢†åŸŸï¼Œç”¨æˆ·é€šå¸¸ä¸ä¼šåœ¨ä¸€è½®äº¤äº’å½“ä¸­æ¸…æ™°åœ°æè¿°è‡ªå·±çš„é—®é¢˜ï¼Œè€Œå½“å‰å¸¸è§çš„å¼€æºåŒ»ç–—é—®ç­”æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼šChatDoctorã€æœ¬è‰(HuaTuoï¼ŒåŸååé©¼ )ã€DoctorGLMã€MedicalGPT-zhï¼‰ä¾§é‡äºè§£å†³å•è½®ç”¨æˆ·æè¿°çš„é—®é¢˜ï¼Œè€Œå¿½ç•¥äº†â€œç”¨æˆ·æè¿°å¯èƒ½å­˜åœ¨ä¸è¶³â€çš„æƒ…å†µã€‚å“ªæ€•æ˜¯å½“å‰å¤§ç«çš„ChatGPTä¹Ÿä¼šå­˜åœ¨ç±»ä¼¼çš„é—®é¢˜ï¼šå¦‚æœç”¨æˆ·ä¸å¼ºåˆ¶é€šè¿‡æ–‡æœ¬æè¿°è®©ChatGPTé‡‡ç”¨ä¸€é—®ä¸€ç­”çš„å½¢å¼ï¼ŒChatGPTä¹Ÿåå‘äºé’ˆå¯¹ç”¨æˆ·çš„æè¿°ï¼Œè¿…é€Ÿç»™å‡ºå®ƒè®¤ä¸ºåˆé€‚çš„å»ºè®®å’Œæ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå®é™…çš„åŒ»ç”Ÿä¸ç”¨æˆ·äº¤è°ˆå¾€å¾€ä¼šå­˜åœ¨â€œåŒ»ç”Ÿæ ¹æ®ç”¨æˆ·å½“å‰çš„æè¿°è¿›è¡ŒæŒç»­å¤šè½®çš„è¯¢é—®â€ã€‚å¹¶ä¸”åŒ»ç”Ÿåœ¨æœ€åæ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ç»¼åˆç»™å‡ºå»ºè®®ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æˆ‘ä»¬æŠŠåŒ»ç”Ÿä¸æ–­é—®è¯¢çš„è¿‡ç¨‹å®šä¹‰ä¸º **è¯¢é—®é“¾ï¼ˆCoQ, Chain of Questioningï¼‰** ï¼Œå½“æ¨¡å‹å¤„äºè¯¢é—®é“¾é˜¶æ®µï¼Œå…¶ä¸‹ä¸€ä¸ªé—®é¢˜é€šå¸¸ç”±å¯¹è¯ä¸Šä¸‹æ–‡å†å²å†³å®šã€‚

<p align="center">
    <img src="./figure/coq.png" width=900px/>
</p>


æˆ‘ä»¬ç»“åˆå½“å‰å¼€æºçš„ä¸­æ–‡åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼ˆ[MedDialog-CN](https://github.com/UCSD-AI4H/Medical-Dialogue-System)ã€[IMCS-V2](https://github.com/lemuria-wchen/imcs21)ã€[CHIP-MDCFNPC](https://tianchi.aliyun.com/dataset/95414)ã€[MedDG](https://tianchi.aliyun.com/dataset/95414)ã€[cMedQA2](https://github.com/zhangsheng93/cMedQA2)ã€[Chinese-medical-dialogue-data](https://github.com/Toyhom/Chinese-medical-dialogue-data)ï¼‰ï¼Œåˆ†æå…¶ä¸­çš„å•è½®/å¤šè½®ç‰¹æ€§ä»¥åŠåŒ»ç”Ÿé—®è¯¢ç‰¹æ€§ï¼Œç»“åˆå®éªŒå®¤é•¿æœŸè‡ªå»ºçš„ç”Ÿæ´»ç©ºé—´å¥åº·å¯¹è¯å¤§æ•°æ®ï¼Œæ„å»ºäº†åƒä¸‡çº§åˆ«è§„æ¨¡çš„æ‰é¹Šå¥åº·å¤§æ•°æ®BianQueCorpusã€‚å¯¹è¯æ•°æ®é€šè¿‡â€œç—…äººï¼šxxx\nåŒ»ç”Ÿï¼šxxx\nç—…äººï¼šxxx\nåŒ»ç”Ÿï¼šâ€çš„å½¢å¼ç»Ÿä¸€ä¸ºä¸€ç§æŒ‡ä»¤æ ¼å¼ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

<p align="center">
    <img src="./figure/dataset_example.png" width=900px/>
</p>


```data
input: "ç—…äººï¼šå…­å²å®å®æ‹‰å¤§ä¾¿éƒ½æ˜¯ä¸€ä¸ªç¤¼æ‹œæˆ–è€…10å¤©æ‰ä¸€æ¬¡æ­£å¸¸å—ï¼Œè¦å»åŒ»é™¢æ£€æŸ¥ä»€ä¹ˆé¡¹ç›®\nåŒ»ç”Ÿï¼šæ‚¨å¥½\nç—…äººï¼šå…­å²å®å®æ‹‰å¤§ä¾¿éƒ½æ˜¯ä¸€ä¸ªç¤¼æ‹œæˆ–è€…10å¤©æ‰ä¸€æ¬¡æ­£å¸¸å—ï¼Œè¦å»åŒ»é™¢æ£€æŸ¥ä»€ä¹ˆé¡¹ç›®\nåŒ»ç”Ÿï¼šå®å®ä¹‹å‰å¤§ä¾¿ä»€ä¹ˆæ ·å‘¢ï¼Ÿå¤šä¹…ä¸€æ¬¡å‘¢\nç—…äººï¼šä¸€èˆ¬éƒ½æ˜¯ä¸€ä¸ªç¤¼æ‹œï¼Œæœ€è¿‘è¿™å‡ ä¸ªæœˆéƒ½æ˜¯10å¤šå¤©\nåŒ»ç”Ÿï¼šå¤§ä¾¿å¹²å—ï¼Ÿ\nç—…äººï¼šæ¯æ¬¡10å¤šå¤©æ‹‰çš„å¾ˆå¤š\nåŒ»ç”Ÿï¼š"
target: "æˆå½¢è¿˜æ˜¯ä¸æˆå½¢å‘¢ï¼Ÿå­©å­åƒé¥­æ€ä¹ˆæ ·å‘¢ï¼Ÿ"
```

è®­ç»ƒæ•°æ®å½“ä¸­æ··åˆäº†å¤§é‡targetæ–‡æœ¬ä¸º**åŒ»ç”Ÿé—®è¯¢çš„å†…å®¹**è€Œéç›´æ¥çš„å»ºè®®ï¼Œè¿™å°†æœ‰åŠ©äºæå‡AIæ¨¡å‹çš„é—®è¯¢èƒ½åŠ›ã€‚


## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/scutcyr/BianQue.git
```

* å®‰è£…ä¾èµ–
éœ€è¦æ³¨æ„çš„æ˜¯torchçš„ç‰ˆæœ¬éœ€è¦æ ¹æ®ä½ çš„æœåŠ¡å™¨å®é™…çš„cudaç‰ˆæœ¬é€‰æ‹©ï¼Œè¯¦æƒ…å‚è€ƒ[pytorchå®‰è£…æŒ‡å—](https://pytorch.org/get-started/previous-versions/)
```bash
cd BianQue
conda env create -n proactivehealthgpt_py38 --file proactivehealthgpt_py38.yml
conda activate proactivehealthgpt_py38

pip install cpm_kernels
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
```

* ã€è¡¥å……ã€‘Windowsä¸‹çš„ç”¨æˆ·æ¨èå‚è€ƒå¦‚ä¸‹æµç¨‹é…ç½®ç¯å¢ƒ
```bash
cd BianQue
conda create -n proactivehealthgpt_py38 python=3.8
conda activate proactivehealthgpt_py38
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip install -r requirements.txt
pip install rouge_chinese nltk jieba datasets
# ä»¥ä¸‹å®‰è£…ä¸ºäº†è¿è¡Œdemo
pip install streamlit
pip install streamlit_chat
```
* ã€è¡¥å……ã€‘Windowsä¸‹é…ç½®CUDA-11.6ï¼š[ä¸‹è½½å¹¶ä¸”å®‰è£…CUDA-11.6](https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)ã€[ä¸‹è½½cudnn-8.4.0ï¼Œè§£å‹å¹¶ä¸”å¤åˆ¶å…¶ä¸­çš„æ–‡ä»¶åˆ°CUDA-11.6å¯¹åº”çš„è·¯å¾„](https://developer.nvidia.com/compute/cudnn/secure/8.4.0/local_installers/11.6/cudnn-windows-x86_64-8.4.0.27_cuda11.6-archive.zip)ï¼Œå‚è€ƒï¼š[win11ä¸‹åˆ©ç”¨condaè¿›è¡Œpytorchå®‰è£…-cuda11.6-æ³›ç”¨å®‰è£…æ€è·¯](https://blog.csdn.net/qq_34740266/article/details/129137794)

* åœ¨Pythonå½“ä¸­è°ƒç”¨BianQue-2.0æ¨¡å‹ï¼š
```python
import torch
from transformers import AutoModel, AutoTokenizer
# GPUè®¾ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# åŠ è½½æ¨¡å‹ä¸tokenizer
model_name_or_path = 'scutcyr/BianQue-2'
model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).half()
model.to(device)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)

# å•è½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
user_input = "æˆ‘çš„å®å®å‘çƒ§äº†ï¼Œæ€ä¹ˆåŠï¼Ÿ"
input_text = "ç—…äººï¼š" + user_input + "\nåŒ»ç”Ÿï¼š"
response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)

# å¤šè½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
# æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨"\nç—…äººï¼š"å’Œ"\nåŒ»ç”Ÿï¼š"åˆ’åˆ†ä¸åŒè½®æ¬¡çš„å¯¹è¯å†å²
# æ³¨æ„ï¼šuser_historyæ¯”bot_historyçš„é•¿åº¦å¤š1
user_history = ['ä½ å¥½', 'æˆ‘æœ€è¿‘å¤±çœ äº†']
bot_history = ['æˆ‘æ˜¯åˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç»“åˆå¤§æ•°æ®è®­ç»ƒå¾—åˆ°çš„æ™ºèƒ½åŒ»ç–—é—®ç­”æ¨¡å‹æ‰é¹Šï¼Œä½ å¯ä»¥å‘æˆ‘æé—®ã€‚']
# æ‹¼æ¥å¯¹è¯å†å²
context = "\n".join([f"ç—…äººï¼š{user_history[i]}\nåŒ»ç”Ÿï¼š{bot_history[i]}" for i in range(len(bot_history))])
input_text = context + "\nç—…äººï¼š" + user_history[-1] + "\nåŒ»ç”Ÿï¼š"

response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)
```

* å¯åŠ¨æœåŠ¡
   
æœ¬é¡¹ç›®æä¾›äº†[bianque_v2_app.py](./bianque_v2_app.py)ä½œä¸ºBianQue-2.0æ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤å³å¯å¼€å¯æœåŠ¡ï¼Œç„¶åï¼Œé€šè¿‡http://<your_ip>:9005è®¿é—®ã€‚
```bash
streamlit run bianque_v2_app.py --server.port 9005
```
ç‰¹åˆ«åœ°ï¼Œåœ¨[bianque_v2_app.py](./bianque_v2_app.py)å½“ä¸­ï¼Œ
å¯ä»¥ä¿®æ”¹ä»¥ä¸‹ä»£ç æ›´æ¢æŒ‡å®šçš„æ˜¾å¡ï¼š
```python
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
```
**å¯¹äºWindowså•æ˜¾å¡ç”¨æˆ·ï¼Œéœ€è¦ä¿®æ”¹ä¸ºï¼š```os.environ['CUDA_VISIBLE_DEVICES'] = '0'```ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼**

å¯ä»¥é€šè¿‡æ›´æ”¹ä»¥ä¸‹ä»£ç æŒ‡å®šæ¨¡å‹è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„ï¼š
```python
model_name_or_path = "scutcyr/BianQue-2"
```

æˆ‘ä»¬è¿˜æä¾›äº†[bianque_v1_app.py](./bianque_v1_app.py)ä½œä¸ºBianQue-1.0æ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œä»¥åŠ[bianque_v1_v2_app.py](./bianque_v1_v2_app.py)ä½œä¸ºBianQue-1.0æ¨¡å‹å’ŒBianQue-2.0æ¨¡å‹çš„è”åˆä½¿ç”¨ç¤ºä¾‹ã€‚

## æ‰é¹Š-2.0
åŸºäºæ‰é¹Šå¥åº·å¤§æ•°æ®BianQueCorpusï¼Œæˆ‘ä»¬é€‰æ‹©äº† [ChatGLM-6B](https://huggingface.co/THUDM/chatglm-6b) ä½œä¸ºåˆå§‹åŒ–æ¨¡å‹ï¼Œç»è¿‡å…¨é‡å‚æ•°çš„æŒ‡ä»¤å¾®è°ƒè®­ç»ƒå¾—åˆ°äº†[æ–°ä¸€ä»£BianQueã€BianQue-2.0ã€‘](https://huggingface.co/scutcyr/BianQue-2)ã€‚ä¸æ‰é¹Š-1.0æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œæ‰é¹Š-2.0æ‰©å……äº†è¯å“è¯´æ˜ä¹¦æŒ‡ä»¤ã€åŒ»å­¦ç™¾ç§‘çŸ¥è¯†æŒ‡ä»¤ä»¥åŠChatGPTè’¸é¦æŒ‡ä»¤ç­‰æ•°æ®ï¼Œå¼ºåŒ–äº†æ¨¡å‹çš„å»ºè®®ä¸çŸ¥è¯†æŸ¥è¯¢èƒ½åŠ›ã€‚ä»¥ä¸‹ä¸ºä¸¤ä¸ªæµ‹è¯•æ ·ä¾‹ã€‚


* æ ·ä¾‹1ï¼šå®å®ç‰¹åˆ«å–œæ¬¢æ‰“å—ï¼Œæ˜¯ä»€ä¹ˆåŸå› å•Šï¼Œè¯¥æ€ä¹ˆé¢„é˜²å•Š
<p align="center">
    <img src="./figure/example_test1.png" width=600px/>
</p>

* æ ·ä¾‹2ï¼šæˆ‘å¤–å©†è¿‘æ¥èº«ä½“è¶Šæ¥è¶Šå·®äº†ï¼Œå¸¦å¥¹å»åŒ»é™¢æ£€æŸ¥ï¼ŒåŒ»ç”Ÿè¯´å¥¹å¾—äº†è‚¾é™è„‰è¡€æ “ï¼Œæˆ‘ä»¬å…¨å®¶éƒ½å¾ˆæ‹…å¿ƒï¼ŒåŒ»ç”Ÿå¼€äº†å¾ˆå¤šæ³¨å°„ç”¨ä½åˆ†å­é‡è‚ç´ é’™ï¼Œæˆ‘æƒ³é—®å®ƒçš„è¯ç†æ¯’ç†ï¼Ÿ
<p align="center">
    <img src="./figure/example_test2.png" width=600px/>
</p>


## æ‰é¹Š-2.0ä¸æ‰é¹Š-1.0è”åˆä½¿ç”¨ï¼Œå…¼é¡¾å¤šè½®é—®è¯¢ä¸å‡ºè‰²çš„å¥åº·å»ºè®®èƒ½åŠ›
é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®ç°è”åˆä½¿ç”¨æ‰é¹Š-2.0ä¸æ‰é¹Š-1.0æ„å»ºä¸»åŠ¨å¥åº·æœåŠ¡ï¼š
```bash
streamlit run bianque_v1_v2_app.py --server.port 9005
```

ä»¥ä¸‹ä¸ºåº”ç”¨ä¾‹å­ï¼šå‰é¢è‹¥å¹²è½®ä¸ºç»è¿‡æ‰é¹Š-1.0æ¨¡å‹è¿›è¡Œé—®è¯¢çš„è¿‡ç¨‹ï¼Œæœ€åä¸€è½®å›å¤ä¸ºç»è¿‡æ‰é¹Š-2.0æ¨¡å‹çš„å›ç­”ã€‚
<p align="center">
    <img src="./figure/example_multi_turn.png" width=600px/>
</p>


## æ‰é¹Š-1.0

**æ‰é¹Š-1.0ï¼ˆBianQue-1.0ï¼‰** æ˜¯ä¸€ä¸ªç»è¿‡æŒ‡ä»¤ä¸å¤šè½®é—®è¯¢å¯¹è¯è”åˆå¾®è°ƒçš„åŒ»ç–—å¯¹è¯å¤§æ¨¡å‹ã€‚æˆ‘ä»¬ç»è¿‡è°ƒç ”å‘ç°ï¼Œåœ¨åŒ»ç–—é¢†åŸŸï¼Œå¾€å¾€åŒ»ç”Ÿéœ€è¦é€šè¿‡å¤šè½®é—®è¯¢æ‰èƒ½è¿›è¡Œå†³ç­–ï¼Œè¿™å¹¶ä¸æ˜¯å•çº¯çš„â€œæŒ‡ä»¤-å›å¤â€æ¨¡å¼ã€‚ç”¨æˆ·åœ¨å’¨è¯¢åŒ»ç”Ÿæ—¶ï¼Œå¾€å¾€ä¸ä¼šåœ¨æœ€åˆå°±æŠŠå®Œæ•´çš„æƒ…å†µå‘ŠçŸ¥åŒ»ç”Ÿï¼Œå› æ­¤åŒ»ç”Ÿéœ€è¦ä¸æ–­è¿›è¡Œè¯¢é—®ï¼Œæœ€åæ‰èƒ½è¿›è¡Œè¯Šæ–­å¹¶ç»™å‡ºåˆç†çš„å»ºè®®ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº† **æ‰é¹Š-1.0ï¼ˆBianQue-1.0ï¼‰** ï¼Œæ‹Ÿåœ¨ **å¼ºåŒ–AIç³»ç»Ÿçš„é—®è¯¢èƒ½åŠ›** ï¼Œä»è€Œè¾¾åˆ°æ¨¡æ‹ŸåŒ»ç”Ÿé—®è¯Šçš„è¿‡ç¨‹ã€‚æˆ‘ä»¬æŠŠè¿™ç§èƒ½åŠ›å®šä¹‰ä¸ºâ€œæœ›é—»é—®åˆ‡â€å½“ä¸­çš„â€œé—®â€ã€‚ç»¼åˆè€ƒè™‘å½“å‰ä¸­æ–‡è¯­è¨€æ¨¡å‹æ¶æ„ã€å‚æ•°é‡ä»¥åŠæ‰€éœ€è¦çš„ç®—åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†[ClueAI/ChatYuan-large-v2](https://huggingface.co/ClueAI/ChatYuan-large-v2)ä½œä¸ºåŸºå‡†æ¨¡å‹ï¼Œåœ¨8å¼  NVIDIA RTX 4090æ˜¾å¡ä¸Šå¾®è°ƒäº†1ä¸ªepochå¾—åˆ°**æ‰é¹Š-1.0ï¼ˆBianQue-1.0ï¼‰**ï¼Œç”¨äºè®­ç»ƒçš„**ä¸­æ–‡åŒ»ç–—é—®ç­”æŒ‡ä»¤ä¸å¤šè½®é—®è¯¢å¯¹è¯æ··åˆæ•°æ®é›†**åŒ…å«äº†è¶…è¿‡900ä¸‡æ¡æ ·æœ¬ï¼Œè¿™èŠ±è´¹äº†å¤§çº¦16å¤©çš„æ—¶é—´å®Œæˆä¸€ä¸ªepochçš„è®­ç»ƒã€‚æˆ‘ä»¬å°†è®¡åˆ’å›´ç»•æ‰é¹Šæ¨¡å‹çš„â€œæœ›é—»é—®åˆ‡â€èƒ½åŠ›ï¼Œç»“åˆåŒ»å­¦ä¸“å®¶çŸ¥è¯†ã€å¤šæ¨¡æ€æŠ€æœ¯ã€å¤šç”Ÿç†ä¿¡å·è®¡ç®—ç­‰ï¼Œè¿›è¡Œå¤šä¸ªç‰ˆæœ¬çš„æ¨¡å‹è¿­ä»£ç ”ç©¶ã€‚æ‰é¹Šï¼ˆBianQueï¼‰æ¨¡å‹æ¬¢è¿ä½ çš„è´¡çŒ®ï¼æˆ‘ä»¬é¼“åŠ±ä½ åœ¨ [BianQue GitHub](https://github.com/scutcyr/BianQue) é¡µé¢æŠ¥å‘Šé—®é¢˜ã€è´¡çŒ® PR å¹¶å‚ä¸è®¨è®ºã€‚æˆ‘ä»¬æœŸå¾…ä¸æ›´å¤šçš„é«˜æ ¡ã€åŒ»é™¢ã€ç ”ç©¶å®éªŒå®¤ã€å…¬å¸ç­‰è¿›è¡Œåˆä½œï¼Œå…±åŒå¼€å±•ä¸‹ä¸€ä»£æ‰é¹Šæ¨¡å‹ç ”ç©¶ã€‚å¯¹äºæ­¤ç±»éœ€æ±‚ï¼ˆä»¥åŠå…¶ä»–ä¸é€‚åˆåœ¨ GitHub ä¸Šæå‡ºçš„éœ€æ±‚ï¼‰ï¼Œè¯·ç›´æ¥å‘é€ç”µå­é‚®ä»¶è‡³ [eeyirongchen@mail.scut.edu.cn](mailto:eeyirongchen@mail.scut.edu.cn)ã€‚


### æ¨¡å‹â€œé—®â€èƒ½åŠ›ç¤ºä¾‹
â€œæœ›é—»é—®åˆ‡â€å››è¯Šæ³•ç”±æ‰é¹Šå‘æ˜ã€‚â€œå››è¯Šæ³•â€ï¼ˆæœ›ã€é—»ã€é—®ã€åˆ‡ï¼‰ï¼Œæ˜¯ä¸­åŒ»è¯Šç—…çš„åŸºæœ¬æ–¹æ³•ã€‚å…¶ä¸­ï¼Œâ€œé—®â€çš„èƒ½åŠ›å¯ä»¥è¢«å»ºæ¨¡åˆ°è¯­è¨€æ¨¡å‹å½“ä¸­ã€‚æˆ‘ä»¬æŠŠAIæ¨¡å‹çš„â€œé—®â€èƒ½åŠ›å®šä¹‰ä¸ºï¼š    
**â€œé—®â€èƒ½åŠ›**ï¼šAIæ¨¡å‹èƒ½å¤Ÿæ ¹æ®ç—…äººè¾“å…¥çš„ä¿¡æ¯ï¼Œç»“åˆåŒ»å­¦çŸ¥è¯†æ¥è¿›è¡Œ**æ°å½“çš„é—®è¯¢**ï¼Œå¹¶ä¸”ç»“åˆè¿›ä¸€æ­¥çš„é—®è¯¢å¾—åˆ°çš„ç—…äººçš„ä¿¡æ¯ï¼Œç»™å‡ºâ€œåˆé€‚çš„è¯Šæ–­æˆ–å»ºè®®â€ã€‚â€œé—®â€çš„è¿‡ç¨‹é€šå¸¸æ˜¯ä¸€ä¸ªå¤šè½®å¯¹è¯è¿‡ç¨‹ã€‚

ä»¥ä¸‹æ˜¯2ä¸ªç®€å•çš„ä¾‹å­ï¼š

* **ä¾‹å­1**    
ç”¨æˆ·ï¼šæˆ‘æœ€è¿‘æ„Ÿè§‰å…¨èº«ç–²æƒ«   
æ‰é¹Š-1.0ï¼šæ˜¯åŠ³ç´¯äº†ï¼Œè¿˜æ˜¯ç†¬å¤œäº†ï¼Ÿ    
ç”¨æˆ·ï¼šè¿™å‘¨éƒ½åœ¨ç†¬å¤œèµ¶è®ºæ–‡    
æ‰é¹Š-1.0ï¼šå—¯ï¼Œç†¬å¤œå®¹æ˜“å¼•èµ·å„ç§ä¸é€‚ï¼Œå¦‚å¤´æ™•ã€ä¹åŠ›ã€å¤±çœ ã€å¤šæ¢¦ç­‰ï¼Œå¤šä¼‘æ¯ï¼Œå¯ä»¥å£æœè°·ç»´ç´ ã€ç»´ç”Ÿç´ B1å’Œå®‰ç¥è¡¥è„‘æ¶²ï¼Œé¿å…ç†¬å¤œã€‚    

* **ä¾‹å­2**   
ç”¨æˆ·ï¼šæˆ‘æœ€è¿‘ç»å¸¸å¤±çœ     
æ‰é¹Š-1.0ï¼šå¤±çœ å¤šä¹…äº†ï¼Ÿ    
ç”¨æˆ·ï¼šä¸¤å‘¨äº†    
æ‰é¹Š-1.0ï¼šç¡çœ æ€ä¹ˆæ ·ï¼Ÿ    
ç”¨æˆ·ï¼šä¸ŠåºŠå‡ å°æ—¶æ‰ç¡å¾—ç€    
æ‰é¹Š-1.0ï¼šå¯ä»¥å£æœä¸€äº›è¯ç‰©   
ç”¨æˆ·ï¼šæœ‰å…·ä½“æ¨èå—   
æ‰é¹Š-1.0ï¼šéœ€è¦å…ˆæ£€æŸ¥ä¸€ä¸‹   
ç”¨æˆ·ï¼šé‚£æˆ‘éœ€è¦åšä»€ä¹ˆæ£€æŸ¥ï¼Ÿ   
æ‰é¹Š-1.0ï¼šå¿ƒç”µå›¾   


### ä½¿ç”¨æ–¹æ³•

#### ç›´æ¥ä½¿ç”¨æ‰é¹Š-1.0æ¨¡å‹

```python
import os
from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


tokenizer = T5Tokenizer.from_pretrained("scutcyr/BianQue-1.0")
model = T5ForConditionalGeneration.from_pretrained("scutcyr/BianQue-1.0")
model = model.to(device)

def preprocess(text):
    text = text.replace("\n", "\\n").replace("\t", "\\t")
    return text

def postprocess(text):
    return text.replace("\\n", "\n").replace("\\t", "\t")

def answer(user_history, bot_history, sample=True, top_p=1, temperature=0.7):
    '''sampleï¼šæ˜¯å¦æŠ½æ ·ã€‚ç”Ÿæˆä»»åŠ¡ï¼Œå¯ä»¥è®¾ç½®ä¸ºTrue;
    top_pï¼š0-1ä¹‹é—´ï¼Œç”Ÿæˆçš„å†…å®¹è¶Šå¤šæ ·
    max_new_tokens=512 lost...'''

    if len(bot_history)>0:
        context = "\n".join([f"ç—…äººï¼š{user_history[i]}\nåŒ»ç”Ÿï¼š{bot_history[i]}" for i in range(len(bot_history))])
        input_text = context + "\nç—…äººï¼š" + user_history[-1] + "\nåŒ»ç”Ÿï¼š"
    else:
        input_text = "ç—…äººï¼š" + user_history[-1] + "\nåŒ»ç”Ÿï¼š"
        return "æˆ‘æ˜¯åˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç»“åˆå¤§æ•°æ®è®­ç»ƒå¾—åˆ°çš„æ™ºèƒ½åŒ»ç–—é—®ç­”æ¨¡å‹æ‰é¹Šï¼Œä½ å¯ä»¥å‘æˆ‘æé—®ã€‚"
    

    input_text = preprocess(input_text)
    print(input_text)
    encoding = tokenizer(text=input_text, truncation=True, padding=True, max_length=768, return_tensors="pt").to(device) 
    if not sample:
        out = model.generate(**encoding, return_dict_in_generate=True, output_scores=False, max_new_tokens=512, num_beams=1, length_penalty=0.6)
    else:
        out = model.generate(**encoding, return_dict_in_generate=True, output_scores=False, max_new_tokens=512, do_sample=True, top_p=top_p, temperature=temperature, no_repeat_ngram_size=3)
    out_text = tokenizer.batch_decode(out["sequences"], skip_special_tokens=True)
    print('åŒ»ç”Ÿ: '+postprocess(out_text[0]))
    return postprocess(out_text[0])

answer_text = answer(user_history=["ä½ å¥½ï¼",
                                   "æˆ‘æœ€è¿‘ç»å¸¸å¤±çœ ",
                                   "ä¸¤å‘¨äº†",
                                   "ä¸ŠåºŠå‡ å°æ—¶æ‰ç¡å¾—ç€"], 
                     bot_history=["æˆ‘æ˜¯åˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç»“åˆå¤§æ•°æ®è®­ç»ƒå¾—åˆ°çš„æ™ºèƒ½åŒ»ç–—é—®ç­”æ¨¡å‹æ‰é¹Šï¼Œä½ å¯ä»¥å‘æˆ‘æé—®ã€‚",
                                  "å¤±çœ å¤šä¹…äº†ï¼Ÿ",
                                  "ç¡çœ æ€ä¹ˆæ ·ï¼Ÿ"])
```

#### ä½¿ç”¨ä¸ªäººæ•°æ®åœ¨æ‰é¹Š-1.0æ¨¡å‹åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¾®è°ƒæ¨¡å‹
* ç¯å¢ƒåˆ›å»º   
ä»¥ä¸‹ä¸ºåœ¨RTX 4090æ˜¾å¡ï¼ŒCUDA-11.6é©±åŠ¨é…ç½®ä¸‹çš„ç¯å¢ƒé…ç½®
```bash
conda env create -n bianque_py38 --file py38_conda_env.yml
conda activate bianque_py38
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
```
* æ•°æ®é›†æ„å»º   
å‚è€ƒ[.data/cMedialog_example.csv](.data/cMedialog_example.csv)æ ¼å¼ï¼Œæ„å»ºä½ çš„æ•°æ®é›†
* åŸºäºæ‰é¹Š-1.0æ¨¡å‹å¾®è°ƒä½ çš„æ¨¡å‹    
ä¿®æ”¹[./scripts/run_train_model_bianque.sh](./scripts/run_train_model_bianque.sh)ï¼Œé€šè¿‡ç»å¯¹è·¯å¾„æŒ‡å®šPREPROCESS_DATAï¼Œå¹¶ä¸”è°ƒæ•´å…¶ä»–å˜é‡ï¼Œç„¶åè¿è¡Œï¼š
```bash
cd scripts
bash run_train_model_bianque.sh
```


## å£°æ˜

**æ‰é¹Š-1.0ï¼ˆBianQue-1.0ï¼‰** å½“å‰ä»…ç»è¿‡1ä¸ªepochçš„è®­ç»ƒï¼Œå°½ç®¡æ¨¡å‹å…·å¤‡äº†ä¸€å®šçš„åŒ»ç–—é—®è¯¢èƒ½åŠ›ï¼Œä½†å…¶ä»ç„¶å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
* è®­ç»ƒæ•°æ®æ¥æºäºå¼€æºæ•°æ®é›†ä»¥åŠäº’è”ç½‘ï¼Œå°½ç®¡æˆ‘ä»¬é‡‡ç”¨äº†ä¸¥æ ¼çš„æ•°æ®æ¸…æ´—æµç¨‹ï¼Œæ•°æ®é›†å½“ä¸­ä»ç„¶ä¸å¯é¿å…åœ°å­˜åœ¨å¤§é‡å™ªå£°ï¼Œè¿™ä¼šä½¿å¾—éƒ¨åˆ†å›å¤äº§ç”Ÿé”™è¯¯ï¼›
* åŒ»ç”Ÿâ€œé—®è¯¢â€æ˜¯ä¸€é¡¹å¤æ‚çš„èƒ½åŠ›ï¼Œè¿™æ˜¯éåŒ»ç”Ÿç¾¤ä½“æ‰€ä¸å…·å¤‡çš„ï¼Œå½“å‰çš„æ¨¡å‹å¯¹äºæ¨¡æ‹Ÿâ€œåŒ»ç”Ÿé—®è¯¢â€è¿‡ç¨‹æ˜¯é€šè¿‡å¤§é‡æ ·æœ¬å­¦ä¹ å¾—åˆ°çš„ï¼Œå› æ­¤åœ¨é—®è¯¢è¿‡ç¨‹å½“ä¸­ï¼Œæœ‰å¯èƒ½å‡ºç°ä¸€äº›å¥‡å¼‚çš„æé—®é£æ ¼ã€‚æ¢ä¸€å¥è¯æ¥è¯´ï¼Œå½“å‰ç‰ˆæœ¬çš„æ¨¡å‹å¼ºåŒ–äº†â€œé—®â€çš„èƒ½åŠ›ï¼Œä½†æ˜¯â€œæœ›â€ã€â€œé—»â€ã€â€œåˆ‡â€çš„èƒ½åŠ›ä»å¾…è¿›ä¸€æ­¥ç ”ç©¶ï¼

**æ‰é¹Š-2.0ï¼ˆBianQue-2.0ï¼‰**ä½¿ç”¨äº†ChatGLM-6B æ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[MODEL_LICENSE](https://github.com/THUDM/ChatGLM-6B/blob/main/MODEL_LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„BianQueæ¨¡å‹è‡´åŠ›äºæå‡å¤§æ¨¡å‹çš„å¥åº·å¯¹è¯èƒ½åŠ›ï¼ˆå¤šè½®é—®è¯¢åŠå¥åº·å»ºè®®ï¼‰ï¼Œç„¶è€Œï¼Œæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬å…·æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œæœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºBianQueæ¨¡å‹çš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨BianQueæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚
* æ‚¨åœ¨ä½¿ç”¨BianQueæ¨¡å‹æ—¶åº”çŸ¥æ‚‰ï¼Œå…¶ä¸èƒ½æ›¿ä»£åŒ»ç”Ÿã€å¿ƒç†åŒ»ç”Ÿç­‰ä¸“ä¸šäººå£«ï¼Œä¸åº”è¿‡åº¦ä¾èµ–ã€æœä»ã€ç›¸ä¿¡æ¨¡å‹çš„è¾“å‡ºï¼Œä¸èƒ½è¿‡åº¦ä¾èµ–äºä¸BianQueæ¨¡å‹èŠå¤©è·å–çš„å¥åº·å»ºè®®ã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±[åå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢](https://www2.scut.edu.cn/ft/main.htm) å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å‘èµ·ï¼Œå¾—åˆ°äº†åå—ç†å·¥å¤§å­¦ä¿¡æ¯ç½‘ç»œå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒã€ç”µå­ä¸ä¿¡æ¯å­¦é™¢ç­‰å­¦é™¢éƒ¨é—¨çš„æ”¯æ’‘ï¼ŒåŒæ—¶è‡´è°¢å¹¿ä¸œçœå¦‡å¹¼ä¿å¥é™¢ã€å¹¿å·å¸‚å¦‡å¥³å„¿ç«¥åŒ»ç–—ä¸­å¿ƒã€ä¸­å±±å¤§å­¦é™„å±ç¬¬ä¸‰åŒ»é™¢ã€åˆè‚¥ç»¼åˆæ€§å›½å®¶ç§‘å­¦ä¸­å¿ƒäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ç­‰åˆä½œå•ä½ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬æ„Ÿè°¢ä»¥ä¸‹åª’ä½“æˆ–å…¬ä¼—å·å¯¹æœ¬é¡¹ç›®çš„æŠ¥é“ï¼ˆæ’åä¸åˆ†å…ˆåï¼‰ï¼š
* åª’ä½“æŠ¥é“
  [äººæ°‘æ—¥æŠ¥](https://wap.peopleapp.com/article/rmh36174922/rmh36174922)ã€[ä¸­å›½ç½‘](https://hs.china.com.cn/gd/83980.html)ã€[å…‰æ˜ç½‘](https://health.gmw.cn/2023-06/13/content_36628062.htm)ã€[TOMç§‘æŠ€](https://tech.tom.com/202306/4526869977.html)ã€[æœªæ¥ç½‘](http://www.zzfuture.cn/news/956.html)ã€[å¤§ä¼—ç½‘](http://linyi.dzwww.com.3xw.site/xinwen/202306/t20230613_202306135667.htm)ã€[ä¸­å›½å‘å±•æŠ¥é“ç½‘](http://www.chinafzbdw.com/computer/13149.html?1686564408)ã€[ä¸­å›½æ—¥æŠ¥ç½‘](http://energy.chinaduily.com.cn/c/2023/15205.html)ã€[æ–°åèµ„è®¯ç½‘](http://www.xinhuazxun.com/world/21762.html?1686564382)ã€[ä¸­åç½‘](https://life.china.com/2023-06/12/content_215815.html)ã€[ä»Šæ—¥å¤´æ¡](https://www.toutiao.com/article/7243412314223952418/)ã€[æœç‹](https://www.sohu.com/a/684501109_120159010)ã€[è…¾è®¯æ–°é—»](https://page.om.qq.com/page/OhSXIMEUtDtdg0rTi6aAoTbg0)ã€[ç½‘æ˜“æ–°é—»](https://www.163.com/dy/article/I70BJ9U00552UJUX.html)ã€[ä¸­å›½èµ„è®¯ç½‘](http://www.chinazxun.com/world/23252.html?1686564532)ã€[ä¸­å›½ä¼ æ’­ç½‘](http://www.chinachbo.com/a/view/11697.html?1686564509)ã€[ä¸­å›½éƒ½å¸‚æŠ¥é“ç½‘](http://www.zgdsbdw.com/meida/11273.html?1686564485)ã€[ä¸­ååŸå¸‚ç½‘](http://www.zhcsww.com/hot/2023/0612/9609.html?1686564434)

* å…¬ä¼—å·
  [å¹¿ä¸œå®éªŒå®¤å»ºè®¾](https://mp.weixin.qq.com/s/gemlKfLg8c-AtjiV7uTUTQ)ã€[æ™ºèƒ½è¯­éŸ³æ–°é’å¹´](https://mp.weixin.qq.com/s/vBMKXUJoAIywkXY2nY60eA)ã€[æ·±åº¦å­¦ä¹ ä¸NLP](https://mp.weixin.qq.com/s/qSHLT8FbvohZESp-UCah6g)ã€[AINLP](https://mp.weixin.qq.com/s/EX3f9WblLKM8K_nSwhno_g)


## å¼•ç”¨
```bib
@misc{chen2023bianque,
      title={BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT}, 
      author={Yirong Chen and Zhenyu Wang and Xiaofen Xing and huimin zheng and Zhipei Xu and Kai Fang and Junhong Wang and Sihang Li and Jieling Wu and Qi Liu and Xiangmin Xu},
      year={2023},
      eprint={2310.15896},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
